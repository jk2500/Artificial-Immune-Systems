import numpy as np
from scipy.spatial import distance
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, RobustScaler
import sklearn.datasets as ds
import matplotlib.pyplot as plt

class RealValuedNSA:
    def __init__(self, detection_radius=0.5, max_detectors=1000):
        self.detection_radius = detection_radius  # Fixed radius for all detectors
        self.max_detectors = max_detectors  # Maximum number of detectors
        self.detectors = []  # List to store the detectors

    def generate_detector(self, self_set):
        # Generate a random detector within the feature bounds
        feature_bounds = [(f.min(), f.max()) for f in self_set.T]
        while True:
            candidate_detector = np.array([np.random.uniform(low, high) for low, high in feature_bounds])
            # Check if the detector is valid (does not match any self sample)
            if all(distance.euclidean(candidate_detector, self_sample) > self.detection_radius for self_sample in self_set):
                return candidate_detector

    def fit(self, self_set):
        # Generate detectors
        while len(self.detectors) < self.max_detectors:
            detector = self.generate_detector(self_set)
            self.detectors.append(detector)

    def predict(self, X):
        # Predict anomalies
        predictions = []
        for x in X:
            # If x falls within the detection radius of any detector, it's an anomaly
            is_anomaly = any(distance.euclidean(x, detector) <= self.detection_radius for detector in self.detectors)
            predictions.append(int(is_anomaly))
        return np.array(predictions)



# Generating a synthetic dataset
X, y = ds.make_classification(n_samples=500, n_features=2, n_informative=2, n_redundant=0, 
                           n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)

# Adding some anomalous data
rng = np.random.default_rng(seed=42)
anomalous_data = rng.uniform(low=-3, high=0, size=(50, 2))
X = np.vstack([X, anomalous_data])
y = np.hstack([y, np.ones(anomalous_data.shape[0])])

# Split the combined data into test and train data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the data
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize and train the RNSA model
rnsa_model = RealValuedNSA(detection_radius=0.1, max_detectors=50)
rnsa_model.fit(X_train_scaled[y_train == 0])

# Evaluate the model
y_pred = rnsa_model.predict(X_test_scaled)
accuracy = np.mean(y_pred == y_test) * 100
print(f"Accuracy: {accuracy}%")


# Plot normal and anomalous data points in the scaled feature space
plt.scatter(X_train_scaled[y_train == 0][:, 0], X_train_scaled[y_train == 0][:, 1],
            label='Normal (Training)', alpha=0.6)
plt.scatter(X_test_scaled[y_test == 1][:, 0], X_test_scaled[y_test == 1][:, 1],
            label='Anomalous (Test)', c='red')

# Plot the detectors generated by the RVNSA algorithm
for detector in rnsa_model.detectors:
    circle = plt.Circle(detector, rnsa_model.detection_radius, color='green', fill=False)
    plt.gca().add_artist(circle)
    plt.plot(*detector, 'go')  # Add the center of the circle

plt.title('Synthetic Dataset with RVNSA Detectors')
plt.xlabel('Feature 1 (scaled)')
plt.ylabel('Feature 2 (scaled)')
plt.legend()
plt.grid(True)
plt.show()
